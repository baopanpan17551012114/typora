# 10种聚类算法

https://mp.weixin.qq.com/s?__biz=MjM5NzEyMzg4MA==&mid=2649469644&idx=6&sn=3f5992bc76bb4233650933dd704c283b&chksm=bec1d08b89b6599d58ab3e91ad35fe78c2f176f1c78a8e4911cb7436d636f0da44297dd14678&scene=27

聚类或聚类分析是无监督学习问题。它通常被用作数据分析技术，用于发现数据中的有趣模式，例如基于其行为的客户群。有许多聚类算法可供选择，对于所有情况，没有单一的最佳聚类算法。相反，最好探索一系列聚类算法以及每种算法的不同配置。在本教程中，你将发现如何在 python 中安装和使用顶级聚类算法。

完成本教程后，你将知道：

- 聚类是在输入数据的特征空间中查找自然组的无监督问题。
- 对于所有数据集，有许多不同的聚类算法和单一的最佳方法。
- 在 scikit-learn 机器学习库的 Python 中如何实现、适配和使用顶级聚类算法。

### 1、亲和力传播聚类算法--AffinityPropagation

AP(Affinity Propagation)通常被翻译为近邻传播算法或者亲和力传播算法，是在2007年的Science杂志上提出的一种新的聚类算法。

AP算法的基本思想是将全部数据点都当作潜在的聚类中心(称之为exemplar)，然后数据点两两之间连线构成一个网络(相似度矩阵)，再通过网络中各条边的消息(responsibility和availability)传递计算出各样本的聚类中心。

**AP算法的优点**

  1） 不需要制定最终聚类族的个数 

  2） 已有的数据点作为最终的聚类中心，而不是新生成一个族中心。 

  3）模型对数据的初始值不敏感。 

  4）对初始相似度矩阵数据的对称性没有要求。 

  5）.相比与k-centers聚类方法，其结果的平方差误差较小。

**AP算法的不足**

  1）AP算法需要事先计算每对数据对象之间的相似度，如果数据对象太多的话，内存放不下，若存在数据库，频繁访问数据库也需要时间。

  2）AP算法的时间复杂度较高，一次迭代大概O(N3)

  3）聚类的好坏受到参考度和阻尼系数的影响。

### 2、层次聚类--AgglomerativeClustering

层次聚类顾名思义就是按照某个层次对样本集进行聚类操作，这里的层次实际上指的就是某种距离定义。
层次聚类最终的目的是消减类别的数量，所以在行为上类似于树状图由叶节点逐步向根节点靠近的过程，这种行为过程又被称为“自底向上”。
更通俗的，层次聚类是将初始化的多个类簇看做树节点，每一步迭代，都是将两两相近的类簇合并成一个新的大类簇，如此反复，直至最终只剩一个类簇（根节点）。
与层次聚类相反的是分裂聚类（divisive clustering），又名 DIANA(Divise Analysis)，它的行为过程为“自顶向下”。

#### 聚类过程

- 数据准备；
- 计算数据集中各样本之间的距离（相似度信息）；
- 使用 连接函数（`linkage function`）将样本进行分组形成层次聚类数（分组依据是上一步计算出来的距离信息），距离相近的样本会被链接在一起；
- 决定在什么地方将层次聚类树截断成多个聚类。



3、综合层次聚类算法

BIRCH(Balanced Iterative Reducing and Clustering using Hierarchies)是一个综合的层次聚类算法。它用到了聚类特征(Clustering Feature, CF)和聚类特征树(CF Tree)两个概念，用于概括聚类描述。聚类特征树概括了聚类的有用信息，并且占用空间较元数据集合小得多，可以存放在内存中，从而可以提高算法在大型数据集合上的聚类速度及可伸缩性。