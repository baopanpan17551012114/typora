# Hive基础知识

**一、什么是Hive**

Hive是一个**数据仓库工具**，它架构在Hadoop之上，并可以将**结构化的数据文件映射为一张表**，并提供**类SQL查询**功能。

这里考虑文章的篇幅，我们对于hadoop(大数据框架)的组件做简要介绍，hadoop中有三个核心的组件：

1. 分布式文件系统：HDFS —— 实现将文件分布式存储在很多的服务器上
2. 分布式运算编程框架：MAPREDUCE —— 实现在很多机器上分布式并行运算
3. 分布式资源调度平台：YARN —— 帮用户调度大量的mapreduce程序，并合理分配运算资源

其中Hive处理的数据存储在HDFS上，Hive分析数据底层实现是MapReduce，执行程序运行在Yarn上**，**说白了：

**Hive可以将SQL程序转换成MapReduce程序，避免了分析人员写MapReduce程序，最终达到提高开发效率和降低开发成本的作用。**

**二、Hive的特点**

1. 简单、容易上手 (提供了类似 sql 的查询语言 hql)，使得精通 sql 但是不了解 Java 编程的人也能很好地进行大数据分析；
2. 灵活性高，可以自定义用户函数 (UDF) 和存储格式；
3. 为超大的数据集设计的计算和存储能力，集群扩展容易;
4. 统一的元数据管理，可与 presto／impala／sparksql 等共享数据；
5. 执行延迟高，不适合做数据的实时处理，但适合做海量数据的离线处理。

**三、hive架构原理**

![img](..\typora-user-images\v2-6a6fa9da2dd57b469482e5f189933470_720w.jpg)

**用户接口：Client**

可以用command-line shell 、thrift／jdbc这两种方式来访问操作数据。

**元数据：Metastore**

在hive中，元数据指的是：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等，所有的元数据默认存储在 Hive 内置的 derby 数据库中，但由于 derby 只能有一个实例，也就是说不能有多个命令行客户端同时访问，所以在实际生产环境中，通常使用 MySQL 代替 derby。

**hadoop**

使用HDFS进行存储，使用MapReduce进行计算。

**驱动器：Driver**

（1）解析器（SQL Parser）：将SQL字符串转换成抽象语法树AST，这一步一般都用第三方工具库完成，比如antlr；对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误。

（2）编译器（Physical Plan）：将AST编译生成逻辑执行计划。

（3）优化器（Query Optimizer）：对逻辑执行计划进行优化。

（4）执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR/Spark。